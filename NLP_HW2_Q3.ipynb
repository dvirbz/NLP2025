{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvirbz/NLP2025/blob/main/NLP_HW2_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo9SxM4GoTO1"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# עיבוד שפה טבעית (20225211) 2024-2025 - תרגיל 2 שאלה 3 (4 נק' מתוך 8)\n",
        "\n",
        "שלום לכולםן!\n",
        "\n",
        "התרגיל שלהלן יתבסס במידה רבה על ההדרכה שעברתןם ב-3/12 ויעקוב באופן כללי אחרי אותם שלבים - ניתן ומומלץ להיעזר ב[מחברת ההדרכה](https://colab.research.google.com/drive/1CVllovh2b6AXCNr6amTNamB9lEttY385?usp=sharing). המטרה היא לבנות רשת נשנית שמתייגת חלקי דיבר עבור השפה טלוגו.\n",
        "\n",
        "בסיום העבודה, הגישו **קובץ pdf** הכולל את כל הפלטים מכל התאים. דרך אפשרית אחת להשיג קובץ pdf היא על-ידי הדפסת הדף (מתוך colab, לא מהדפדפן) ולבחור \"מדפסת\" ישירה ל-pdf. אני מזכיר שמועד ההגשה עבור כל חלקי התרגיל הינו 16/12/24, 15:59.\n",
        "\n",
        "בהצלחה,\n",
        "\n",
        "-- יובל\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpXCrjswYMs7"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# התקנות\n",
        "\n",
        "כמו במקרה הקודם, נוכל להשתמש בחבילות עיבוד השפה של [האגינגפייס](https://huggingface.co/) על-מנת לטעון את הדאטא.\n",
        "כיוון שאנחנו טוענים דאטא בפורמט מטוקנז של יוניברסל דפנדנסיז (UD), נצטרך להתקין גם חבילה התומכת בו.\n",
        "אפשר להתעלם מהתקלה שהוא מצהיר עליה.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GaUS889WNXb"
      },
      "source": [
        "!pip install datasets -q\n",
        "!pip install tokenizers -q\n",
        "!pip install conllu -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oXNwyidYsQO"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# ייבוא\n",
        "\n",
        "נצטרך כמעט את כל החבילות שהתקנו עבור הרשת הנשנית למסמכים.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64YQUQ9eWXvn"
      },
      "source": [
        "import matplotlib.pyplot as plt  # for plotting\n",
        "import pandas as pd  # only to show some data in a nice table\n",
        "import torch\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm  # progress bar"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cDYt9AkCylC"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# זרע הפורענות\n",
        "\n",
        "משהו שכדאי לעשות בזמן שמפתחים מודל הוא להמעיט באקראיות ככל הניתן.\n",
        "בחבילות הנומריות של פייתון כמו numpy ו-pytorch יש הרבה מאוד אלמנטים אקראיים, כמו איך פרמטרים מאותחלים, או באיזה סדר נופל דאטאסט אם אנחנו בוחרים לערבב אותו בכל איטרציה (מומלץ באופן כללי, לא נממש הפעם).\n",
        "הדרך שלנו לשלוט באלמנטים האלה כדי שיהיו זהים בכל הרצה (ובין היתר, להקל על בדיקת התרגיל) היא לקבוע זרע אקראי בתחילת ההרצה, שממנו תנבע האקראיות באופן דטרמיניסטי. הבה:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDxDrdLrDajL"
      },
      "source": [
        "SEED = 5785\n",
        "\n",
        "import random\n",
        "from numpy import random as nprnd\n",
        "\n",
        "random.seed(SEED)\n",
        "nprnd.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZSnW0l_n-al"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# מה בדאטא?\n",
        "\n",
        "כמו בניתוח סנטימנט, אנחנו רוצים לדעת עם מה יש לנו עסק. לטעון מתוך UD זה קל עם חבילת datasets, ובשביל לגשת לשדות השונים, ניתן להיעזר ב[דף התיעוד](https://huggingface.co/datasets/universal_dependencies).\n",
        "אותנו מעניין רק הטקסט וחלקי הדיבר UPOS (בשלב הזה) ולכן נסתכל על כמה דוגמאות:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnlL82KYm9G2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "10c724d0-7034-45b1-b5ee-44edb88b1c14"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "dataset = load_dataset(\n",
        "   'universal_dependencies', 'te_mtg', trust_remote_code=True)\n",
        "dataset.set_format(type=\"pandas\", columns=[\"text\", \"tokens\", \"upos\"])\n",
        "dataset['validation'][:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               text                                   tokens  \\\n",
              "0         మనం ఎందుకు అన్నం తింటాం ?          [మనం, ఎందుకు, అన్నం, తింటాం, ?]   \n",
              "1             నువ్వు పని చెయ్యాలి .               [నువ్వు, పని, చెయ్యాలి, .]   \n",
              "2  నేను ఆ పని చెయ్యాల్సి వచ్చింది .  [నేను, ఆ, పని, చెయ్యాల్సి, వచ్చింది, .]   \n",
              "3       మీ తల్లిదండ్రుల ఊరు ఏమిటి ?        [మీ, తల్లిదండ్రుల, ఊరు, ఏమిటి, ?]   \n",
              "4               అవి మా ఇళ్ళ గోడలు .                [అవి, మా, ఇళ్ళ, గోడలు, .]   \n",
              "5                  ఇది పళ్ళ బుట్ట .                    [ఇది, పళ్ళ, బుట్ట, .]   \n",
              "6           ఇవ్వేళ ఆమె ఇక్కడ లేదు .            [ఇవ్వేళ, ఆమె, ఇక్కడ, లేదు, .]   \n",
              "7           నిన్న మేము ఊళ్ళో లేము .            [నిన్న, మేము, ఊళ్ళో, లేము, .]   \n",
              "8          దుకాణాల్లో బియ్యం లేవు .            [దుకాణాల్లో, బియ్యం, లేవు, .]   \n",
              "9         అతను నన్ను వెళ్ళమన్నాడు .           [అతను, నన్ను, వెళ్ళమన్నాడు, .]   \n",
              "\n",
              "                    upos  \n",
              "0     [11, 14, 0, 16, 1]  \n",
              "1         [11, 0, 16, 1]  \n",
              "2  [11, 8, 0, 16, 16, 1]  \n",
              "3      [11, 0, 0, 11, 1]  \n",
              "4      [11, 11, 0, 0, 1]  \n",
              "5          [11, 0, 0, 1]  \n",
              "6     [0, 11, 14, 16, 1]  \n",
              "7     [14, 11, 0, 16, 1]  \n",
              "8          [0, 0, 16, 1]  \n",
              "9        [11, 11, 16, 1]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bc4c756-da75-4af6-b940-cf71d09245cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>upos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>మనం ఎందుకు అన్నం తింటాం ?</td>\n",
              "      <td>[మనం, ఎందుకు, అన్నం, తింటాం, ?]</td>\n",
              "      <td>[11, 14, 0, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>నువ్వు పని చెయ్యాలి .</td>\n",
              "      <td>[నువ్వు, పని, చెయ్యాలి, .]</td>\n",
              "      <td>[11, 0, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>నేను ఆ పని చెయ్యాల్సి వచ్చింది .</td>\n",
              "      <td>[నేను, ఆ, పని, చెయ్యాల్సి, వచ్చింది, .]</td>\n",
              "      <td>[11, 8, 0, 16, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>మీ తల్లిదండ్రుల ఊరు ఏమిటి ?</td>\n",
              "      <td>[మీ, తల్లిదండ్రుల, ఊరు, ఏమిటి, ?]</td>\n",
              "      <td>[11, 0, 0, 11, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>అవి మా ఇళ్ళ గోడలు .</td>\n",
              "      <td>[అవి, మా, ఇళ్ళ, గోడలు, .]</td>\n",
              "      <td>[11, 11, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ఇది పళ్ళ బుట్ట .</td>\n",
              "      <td>[ఇది, పళ్ళ, బుట్ట, .]</td>\n",
              "      <td>[11, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ఇవ్వేళ ఆమె ఇక్కడ లేదు .</td>\n",
              "      <td>[ఇవ్వేళ, ఆమె, ఇక్కడ, లేదు, .]</td>\n",
              "      <td>[0, 11, 14, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>నిన్న మేము ఊళ్ళో లేము .</td>\n",
              "      <td>[నిన్న, మేము, ఊళ్ళో, లేము, .]</td>\n",
              "      <td>[14, 11, 0, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>దుకాణాల్లో బియ్యం లేవు .</td>\n",
              "      <td>[దుకాణాల్లో, బియ్యం, లేవు, .]</td>\n",
              "      <td>[0, 0, 16, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>అతను నన్ను వెళ్ళమన్నాడు .</td>\n",
              "      <td>[అతను, నన్ను, వెళ్ళమన్నాడు, .]</td>\n",
              "      <td>[11, 11, 16, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bc4c756-da75-4af6-b940-cf71d09245cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bc4c756-da75-4af6-b940-cf71d09245cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bc4c756-da75-4af6-b940-cf71d09245cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee7d7649-036b-46d7-b95d-8f62bb6c0ce9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee7d7649-036b-46d7-b95d-8f62bb6c0ce9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee7d7649-036b-46d7-b95d-8f62bb6c0ce9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset['validation'][:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0c26\\u0c41\\u0c15\\u0c3e\\u0c23\\u0c3e\\u0c32\\u0c4d\\u0c32\\u0c4b \\u0c2c\\u0c3f\\u0c2f\\u0c4d\\u0c2f\\u0c02 \\u0c32\\u0c47\\u0c35\\u0c41 .\",\n          \"\\u0c28\\u0c41\\u0c35\\u0c4d\\u0c35\\u0c41 \\u0c2a\\u0c28\\u0c3f \\u0c1a\\u0c46\\u0c2f\\u0c4d\\u0c2f\\u0c3e\\u0c32\\u0c3f .\",\n          \"\\u0c07\\u0c26\\u0c3f \\u0c2a\\u0c33\\u0c4d\\u0c33 \\u0c2c\\u0c41\\u0c1f\\u0c4d\\u0c1f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upos\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMNqAk-MSUhe"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "המממ. קצת פחות ברור מה שקורה פה מאשר בדוגמת המסמכים השלמים. קודם כל, אנחנו לא דוברים טלוגו. [הנה](https://en.wikipedia.org/wiki/Telugu_language) ערך הויקיפדיה שלה, ו[הנה](https://wals.info/languoid/lect/wals_code_tel) הערך שלה ב-WALS, משאב טיפולוגי שסקרנו בשיעורי המבוא. WALS יספר לנו על תכונות של השפה שאולי יעזרו לנו להבין בהמשך אם יש תופעות שכדאי להתייחס אליהן מפורשות.\n",
        "\n",
        "הדבר השני שאנחנו מתקשים איתו הוא פורמט התגים, שמופיעים כאן אחרי שכבר מופו לאינדקסים ע\"י מי שהזין אותם לשרתי האגינגפייס. למזלנו, דאגו לנו גם לשמירת המיפוי בתוך הדאטאסט, וניתן לגשת אליו מתוך כל אחד מחיתוכי הדאטא (splits).\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsoWmt7NYqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421ceec7-9f7a-4478-8a96-e1436dcbdd1e"
      },
      "source": [
        "val_tags = dataset['validation'].features['upos'].feature.names\n",
        "[f'{i:2}: {p}' for (i,p) in enumerate(val_tags)]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' 0: NOUN',\n",
              " ' 1: PUNCT',\n",
              " ' 2: ADP',\n",
              " ' 3: NUM',\n",
              " ' 4: SYM',\n",
              " ' 5: SCONJ',\n",
              " ' 6: ADJ',\n",
              " ' 7: PART',\n",
              " ' 8: DET',\n",
              " ' 9: CCONJ',\n",
              " '10: PROPN',\n",
              " '11: PRON',\n",
              " '12: X',\n",
              " '13: _',\n",
              " '14: ADV',\n",
              " '15: INTJ',\n",
              " '16: VERB',\n",
              " '17: AUX']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "סקירת-שפיות קצרה של הדאטא מהתא הקודם תראה לנו שבאמת ברוב המשפטים יש פועל (16), כפי שאנו מצפים מכל שפה, שיש הרבה שמות עצם (0), ושסימני הפיסוק מקבילים לתג המתאים (1).\n",
        "\n",
        "1. רשמו את קוד התכונה (Fid) מערך ה-WALS שבזכותו אנחנו לא מופתעיםות ממיקומי הפעלים שראינו במשפטי הדוגמה.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "jP9YhvY38PoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "---\n",
        "\n",
        "**81A**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "ZWOAiBisDwPO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8i8-2zeTLk9"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "כיוון שאנחנו חשדניםות מטבענו, ולא נרצה שנאמן את המודל על רשימת תגים מסוימת ואח\"כ נבחן אותו על אינדקסים לא-תואמים (מה שיכול לגרום לכך שכל החיזויים שלנו לשמות עצם יפורשו כחיזויים לפעלים, למשל), נכתוב קוד קצר שמוודא שסדר התגים זהה עבור אימון, ולידציה ומבחן.\n",
        "\n",
        "2. כתבו קוד שמוודא את סדר התגים לשלושת חלקי הדאטאסט. ניתן להשתמש בפונקציית `assert`.\n",
        "**מגישים.ות ביחיד.ה פטוריםות מהסעיף**\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G_d1qP7TnpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17725ced-3d72-4dbd-bc35-1ac3bd21012c"
      },
      "source": [
        "### for exercise 2 ###\n",
        "\n",
        "train_tags = dataset['train'].features['upos'].feature.names\n",
        "test_tags = dataset['test'].features['upos'].feature.names\n",
        "ordered_val_tags = [f'{i:2}: {p}' for (i,p) in enumerate(val_tags)]\n",
        "ordered_train_tags = [f'{i:2}: {p}' for (i,p) in enumerate(train_tags)]\n",
        "ordered_test_tags = [f'{i:2}: {p}' for (i,p) in enumerate(test_tags)]\n",
        "assert ordered_train_tags == ordered_val_tags == ordered_test_tags\n",
        "print(f\"{ordered_train_tags=}\\n{ordered_test_tags=}\\n{ordered_val_tags=}\")\n",
        "###"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ordered_train_tags=[' 0: NOUN', ' 1: PUNCT', ' 2: ADP', ' 3: NUM', ' 4: SYM', ' 5: SCONJ', ' 6: ADJ', ' 7: PART', ' 8: DET', ' 9: CCONJ', '10: PROPN', '11: PRON', '12: X', '13: _', '14: ADV', '15: INTJ', '16: VERB', '17: AUX']\n",
            "ordered_test_tags=[' 0: NOUN', ' 1: PUNCT', ' 2: ADP', ' 3: NUM', ' 4: SYM', ' 5: SCONJ', ' 6: ADJ', ' 7: PART', ' 8: DET', ' 9: CCONJ', '10: PROPN', '11: PRON', '12: X', '13: _', '14: ADV', '15: INTJ', '16: VERB', '17: AUX']\n",
            "ordered_val_tags=[' 0: NOUN', ' 1: PUNCT', ' 2: ADP', ' 3: NUM', ' 4: SYM', ' 5: SCONJ', ' 6: ADJ', ' 7: PART', ' 8: DET', ' 9: CCONJ', '10: PROPN', '11: PRON', '12: X', '13: _', '14: ADV', '15: INTJ', '16: VERB', '17: AUX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDc3lmI6Y959"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# טוקנייזר\n",
        "\n",
        "בעית הטיקנוז שלנו קלה אפילו יותר מזו שהיתה בניתוח סנטימנט. המסמכים שלנו באים עם חלוקה לטוקנים מראש, ולכן אפשר פשוט להעביר לטוקנייזר שנבנה בתור ברירת מחדל את הפרמטר לפיו המידע שהוא מקבל כבר עבר \"טרום-טוקניזציה\".\n",
        "על-כן:\n",
        "1. נטען את הדאטאסט\n",
        "1. ניצור טוקנייזר פשוט\n",
        "1. נגדיר לו את התמנית הלא ידועה `UNK` ואת תמנית הריפוד `PAD`\n",
        "1. נאמן את הטוקנייזר\n",
        "1. נספר לו איך לרפד.\n",
        "\n",
        "אחר-כך נצטרך לטפל גם בטוקנייזר עבור התגים, בעיקר כדי לשמור על מדיניות ריפוד אחידה (המודולים ב-`torch` יצפו לאורך רצפים אחידים בין הקלט לתגים).\n",
        "בשני המקרים נעשה משהו קצת מלוכלך בשביל ליצור לטוקנייזר מחרוזת כקלט. עבור הטוקנים, נגדיר פונקציה שמכניסה רווחים שאחר-כל האימון של הטוקנייזר יוציא, ועבוד התגים, כיוון שהם נטענו בפורמט `int`, נריץ עליהם פונקציית `str()`.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfVHzTiqWlDA"
      },
      "source": [
        "PAD_ID = 0\n",
        "\n",
        "def map_instance_to_whitespace_tokenizable_text(inst) -> str:\n",
        "    return \" \".join(inst['tokens'])\n",
        "\n",
        "def make_tokenizers():\n",
        "    dataset = load_dataset(\"universal_dependencies\", \"te_mtg\", split=\"train\")\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"<UNK>\"))\n",
        "    tokenizer.pre_tokenizer = WhitespaceSplit()\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"<PAD>\", \"<UNK>\"])\n",
        "    tokenizer.train_from_iterator([map_instance_to_whitespace_tokenizable_text(i) for i in dataset],\n",
        "                                  trainer=trainer,\n",
        "                                  length=len(dataset))\n",
        "    tokenizer.enable_padding(pad_id=PAD_ID, pad_token=\"<PAD>\")\n",
        "\n",
        "    tag_tokenizer = Tokenizer(WordLevel(vocab={str(i): i for i in range(len(val_tags)+1)}))\n",
        "    tag_tokenizer.enable_padding(pad_id=len(val_tags), pad_token=str(len(val_tags)))\n",
        "    return tokenizer, tag_tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5X5IGIXUKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63af871-24da-41b4-b7d8-6a928b7ce59f"
      },
      "source": [
        "tokenizer, tag_tokenizer = make_tokenizers()\n",
        "\n",
        "tokenizer.save(\"ud-te-tokenizer.json\", pretty=True)\n",
        "tag_tokenizer.save(\"ud-te-tag-tokenizer.json\", pretty=True)\n",
        "\n",
        "print(tokenizer.get_vocab_size())\n",
        "print(tag_tokenizer.get_vocab_size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1745\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGKFvg8Gzin"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "שימו לב שקיבלנו אוצר מילים די קטן לטוקנים, כיאה לדאטאסט קטן. הולכים להיות לנו הרבה מאוד `UNK` בולידציה ובטסט.\n",
        "19 תגים זה המספר הרצוי, שכן יש 18 תגים בסכימת UPOS, והוספנו תג ריפוד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1qaENkhcWSs"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# בניית מתייג חלקי דיבר\n",
        "\n",
        "נתחיל בהמרת המעבד שלנו ל-GPU:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SljbOmVeXVyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d3f589a-59bf-4dce-c2ad-4db21c401a6e"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7EvpX4Lc3uf"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## הגדרת המודל\n",
        "\n",
        "המודל הבסיסי שלנו זהה לזה שהשתמשנו בו עבור הרשת לסיווג טקסט שלם, עם הבדל אחד מאוד חשוב: הפלט שלה צריך להיות ברמת הטוקן; לא לוקחים רק את האחרון אלא את כל הסט שיוצא מה-LSTM, ואותו מעבירים לשכבה לינארית.\n",
        "\n",
        "**שימו לב:** בהמשך נראה שפונקציית ההפסד שלנו מקבלת ציונים לא-מנורמלים עבור הקלאסים (חלקי דיבר, במקרה שלנו) ומבצעת את ה-`softmax` כחלק מהחישוב. אל תעבירו את הפלט בפונקציה שמבצעת חישוב דומה.\n",
        "\n",
        "3. ממשו את `__init__()` ואת `forward()`. שימו לב לפרמטרים שהשתנו ביחס להדרכת תיוג המסמכים.\n",
        "\n",
        "![](https://discuss.pytorch.org/uploads/default/original/2X/e/e7496a33d835f085d800ee17c0ade05895a89551.png)<br>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4z8A8RdXiQl"
      },
      "source": [
        "class PosTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_dim: int,\n",
        "                 hidden_size: int,\n",
        "                 num_tags: int,\n",
        "                 num_layers: int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        ### for exercise 3.1 ###\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_tags = num_tags\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(tokenizer.get_vocab_size(),\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=tokenizer.padding[\"pad_id\"])\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=False)\n",
        "        self.fc = nn.Linear(hidden_size, num_tags)\n",
        "        # self.softmax = nn.Softmax(dim=2)\n",
        "        ###\n",
        "\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "        ### for exercise 3.2 ###\n",
        "        embed = self.embedding(x)\n",
        "        output, _ = self.lstm(embed)\n",
        "        print(f\"{output.shape=}\")\n",
        "        out = self.fc(output)\n",
        "        # out = self.softmax(out)\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3BB1099OyZK"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## אימון ו-ולידציה\n",
        "\n",
        "ההבדל העיקרי בפרקטיקת האימון אל מול סיווג מסמכים היא שיש גרדיאנט שמחושב עבור כל אחד מהטוקנים בנפרד: לכל אצווה (batch) יהיו לנו מספר תחזיות לא כגודלה אלא כסכום אורכי המשפטים שבה.\n",
        "עיינו בקפידה ב[תיעוד](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) מודול ההפסד שנשתמש בו וחישבו היטב מה הקלט שלו צריך להיות.\n",
        "\n",
        "4.1 ממשו את חישוב ההפסד ופעפועו. שימו לב לגדלי הטנסורים המשתתפים. שני רמזים בהקשר זה:\n",
        "* אין לדאוג עדיין לטוקני הריפוד. אנחנו לא נרצה להשתמש בתחזיות שלהם כמובן, אבל הטיפול בהם קורה בשלב אתחול ההפסד.\n",
        "* גשו לתיעוד של `torch.tensor` ועמדו על ההבדל בין הפעולות `view()` ו-`permute()`.\n",
        "* **מגישים ביחיד.ה פטוריםות מהסעיף - פנו אליי עד ליום 10/12 בשעה 13:59 לקבלת שורות הקוד (מילואימניקים עד 14/12 ב-23:59).**\n",
        "\n",
        "4.2. ממשו את חישוב המטריקה. אנו נמדוד דיוק פשוט (accuracy), ולצורך כך אותחלו עבורכם משתני-עזר לפני הלולאה. כאן אנחנו כן דואגים לטוקני הריפוד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX7neNCaX07e"
      },
      "source": [
        "def train(model: PosTagger,\n",
        "          optimizer: optim.Optimizer,\n",
        "          loss_fn: nn.CrossEntropyLoss,\n",
        "          dataloader: DataLoader) -> dict:\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        sentences = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        probs = model(sentences)\n",
        "        ### for exercise 4.1 ###\n",
        "        print(f\"{probs.shape=}\")\n",
        "        softmax = nn.Softmax(dim=2)\n",
        "        probs = softmax(probs)\n",
        "        probs = probs.permute((0,2,1))\n",
        "        print(f\"{probs.shape=}\")\n",
        "        B, N = labels.shape\n",
        "        print(f\"{labels.shape=}\")\n",
        "        # labels = labels.view(-1)\n",
        "        # print(f\"{labels.shape=}\")\n",
        "\n",
        "        loss = loss_fn(probs, labels)\n",
        "        print(\"Calu2\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ###\n",
        "        preds = probs.argmax(dim=2)\n",
        "\n",
        "        ### for exercise 4.2 ###\n",
        "        N = labels.shape[0]\n",
        "        total += N\n",
        "        correct += (preds == labels).sum()\n",
        "        ###\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def evaluate(model: PosTagger,\n",
        "             dataloader: torch.utils.data.DataLoader) -> dict:\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # operations done in this block will not contribute to gradients\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            sentences = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            probs = model(sentences)\n",
        "            preds = probs.argmax(dim=2)\n",
        "\n",
        "            ### for exercise 4.2 ###\n",
        "\n",
        "            ### (the same code from train() should work)\n",
        "\n",
        "    return correct / total"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkwR_UESPvjV"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# רגע האמת\n",
        "\n",
        "נחבר הכל ביחד. נגדיר את הקבועים שלנו, שבהמשך יהיו היפר-פרמטרים.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmL1nlMV_aA"
      },
      "source": [
        "BATCH_SIZE = 24\n",
        "EMB_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "EPOCHS = 5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwzQHeJiWQKm"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "נגדיר פונקציית-עזר לחילוץ מחרוזות האינדקסים מתוך מיפויי התגים, ונטען בעזרתה את הדאטאסט.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlGbCxPVVJVy"
      },
      "source": [
        "def deep_stringify(x):\n",
        "    if type(x) == int:\n",
        "        return str(x)\n",
        "    return [deep_stringify(a) for a in x]\n",
        "\n",
        "dataset = load_dataset(\"universal_dependencies\", \"te_mtg\")\n",
        "dataset = dataset.map(lambda ins: {\n",
        "    \"input_ids\": [e.ids for e in tokenizer.encode_batch(ins['tokens'],\n",
        "                                                        is_pretokenized=True)],\n",
        "    \"labels\": [e.ids for e in tag_tokenizer.encode_batch(deep_stringify(ins['upos']),\n",
        "                                                        is_pretokenized=True)],\n",
        "}, batched=True, batch_size=BATCH_SIZE)\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"], )\n",
        "\n",
        "train_dataloader = DataLoader(dataset[\"train\"], batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(dataset[\"validation\"], batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset[\"test\"], batch_size=BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGUSebxWgbC"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "נאתחל מודל, מאפטם ופונקציית הפסד.\n",
        "\n",
        "5. אתחלו את פונקציית ההפסד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkqjbfQDYAh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "93842da4-22c3-4765-a222-1e9359ba6476"
      },
      "source": [
        "model = PosTagger(embedding_dim=EMB_DIM,\n",
        "                  hidden_size=HIDDEN_DIM,\n",
        "                  num_layers=NUM_LAYERS,\n",
        "                  num_tags=len(val_tags)).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "### for exercise 5\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "###\n",
        "\n",
        "train_accuracies = []\n",
        "validation_accuracies = []\n",
        "for epoch in range(EPOCHS):\n",
        "    train_acc = train(model, optimizer, loss_fn,\n",
        "                          train_dataloader)\n",
        "    val_acc = evaluate(model, val_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}:\")\n",
        "    print(f\"Training Accuracy: {100 * train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy: {100 * val_acc:.2f}%\")\n",
        "    train_accuracies.append(train_acc)\n",
        "    validation_accuracies.append(val_acc)\n",
        "\n",
        "plt.title(\"Accuracy by Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(train_accuracies, label=\"Training\")\n",
        "plt.plot(validation_accuracies, label=\"Validation\")\n",
        "plt.legend();"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f45ac9fabd10>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   num_tags=len(val_tags)).to(device)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmOGxQclpgeM"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# ניתוח\n",
        "\n",
        "6. בתיבת הטקסט להלן, תארו את הגרף שיצא לכםן לעיל. הציעו לפחות שני שינויים בהיפר-פרמטרים שלדעתכןם עשויים לשפר את התוצאה **וממשו אותם**. לכל ניסוי שכפלו את תיבת הקוד לעיל, שנו את מה שצריך, והריצו מחדש. **השתמשו בשמות משתנים חדשים עבור המודלים והתוצאות**. ניתן לוותר על הדפסות המספרים באפוקי הביניים ולהסתפק בתוצאות הסוף ובגרף.\n",
        "\n",
        "7. שנו מאפיין של הניסוי ש**אינו** אחד מההיפר-פרמטרים המוגדרים. למשל, השתמשו בקלאס אחר מ-pytorch עבור הרשת הנשנית, המאפטם, או משהו אחר לבחירתכןם. או הוסיפו שכבה לינארית למודל.\n",
        "**מגישים ביחיד.ה פטוריםות מסעיף 7**\n",
        "\n",
        "האם השינויים אכן הועילו?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKmLgXFAYsdU"
      },
      "source": [
        "## <דווחו כאן>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHDyp3C3YBAv"
      },
      "source": [
        "### for exercise 6-7 ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiHHRen_YDe-"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## טסט\n",
        "\n",
        "8. מצאו את המודל הטוב ביותר מאלה שניסיתם עד כה והריצו (פעם אחת בלבד) על הטסט. הקבוצה עם התוצאה הטובה ביותר תקבל בונוס נקודה לציון הסופי בקורס.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBuAY515Y4Oy"
      },
      "source": [
        "### for exercise 8 ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7vROGFtTefk"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# העשרה - שיכונים מן המוכן\n",
        "\n",
        "למי שמעונייןת, ניתן להוריד שיכונים (embeddings) של טלוגו ממאגר שנקרא fastText. הקוד להורדת המודל, טעינתו והתאמתו למימד הבעייה שלנו נתון. שינוי הטוקנייזר והמודל לצורך שימוש במתייג שלנו - עליכןם. **ללא ציון**.\n",
        "\n",
        "שימו לב שהורדת השיכונים לוקחת זמן רב (מדובר בכ-4GB). היאזרו בסבלנות או בפרק מנטפליקס.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1e3VbpXZLCa"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrDARO-sTS7T"
      },
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('te', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.te.300.bin')\n",
        "fasttext.util.reduce_model(ft, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DA6S6ytDd2b"
      },
      "source": [
        "!rm cc.te.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BHyJs8jHIGz"
      },
      "source": [
        "len(ft.get_words())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBYb1xzHQw4"
      },
      "source": [
        "ft.get_words()[5000:5005]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}