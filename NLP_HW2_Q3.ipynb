{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvirbz/NLP2025/blob/main/NLP_HW2_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo9SxM4GoTO1"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# עיבוד שפה טבעית (20225211) 2024-2025 - תרגיל 2 שאלה 3 (4 נק' מתוך 8)\n",
        "\n",
        "שלום לכולםן!\n",
        "\n",
        "התרגיל שלהלן יתבסס במידה רבה על ההדרכה שעברתןם ב-3/12 ויעקוב באופן כללי אחרי אותם שלבים - ניתן ומומלץ להיעזר ב[מחברת ההדרכה](https://colab.research.google.com/drive/1CVllovh2b6AXCNr6amTNamB9lEttY385?usp=sharing). המטרה היא לבנות רשת נשנית שמתייגת חלקי דיבר עבור השפה טלוגו.\n",
        "\n",
        "בסיום העבודה, הגישו **קובץ pdf** הכולל את כל הפלטים מכל התאים. דרך אפשרית אחת להשיג קובץ pdf היא על-ידי הדפסת הדף (מתוך colab, לא מהדפדפן) ולבחור \"מדפסת\" ישירה ל-pdf. אני מזכיר שמועד ההגשה עבור כל חלקי התרגיל הינו 16/12/24, 15:59.\n",
        "\n",
        "בהצלחה,\n",
        "\n",
        "-- יובל\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpXCrjswYMs7"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# התקנות\n",
        "\n",
        "כמו במקרה הקודם, נוכל להשתמש בחבילות עיבוד השפה של [האגינגפייס](https://huggingface.co/) על-מנת לטעון את הדאטא.\n",
        "כיוון שאנחנו טוענים דאטא בפורמט מטוקנז של יוניברסל דפנדנסיז (UD), נצטרך להתקין גם חבילה התומכת בו.\n",
        "אפשר להתעלם מהתקלה שהוא מצהיר עליה.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GaUS889WNXb"
      },
      "source": [
        "!pip install datasets -q\n",
        "!pip install tokenizers -q\n",
        "!pip install conllu -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oXNwyidYsQO"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# ייבוא\n",
        "\n",
        "נצטרך כמעט את כל החבילות שהתקנו עבור הרשת הנשנית למסמכים.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64YQUQ9eWXvn"
      },
      "source": [
        "import matplotlib.pyplot as plt  # for plotting\n",
        "import pandas as pd  # only to show some data in a nice table\n",
        "import torch\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm  # progress bar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cDYt9AkCylC"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# זרע הפורענות\n",
        "\n",
        "משהו שכדאי לעשות בזמן שמפתחים מודל הוא להמעיט באקראיות ככל הניתן.\n",
        "בחבילות הנומריות של פייתון כמו numpy ו-pytorch יש הרבה מאוד אלמנטים אקראיים, כמו איך פרמטרים מאותחלים, או באיזה סדר נופל דאטאסט אם אנחנו בוחרים לערבב אותו בכל איטרציה (מומלץ באופן כללי, לא נממש הפעם).\n",
        "הדרך שלנו לשלוט באלמנטים האלה כדי שיהיו זהים בכל הרצה (ובין היתר, להקל על בדיקת התרגיל) היא לקבוע זרע אקראי בתחילת ההרצה, שממנו תנבע האקראיות באופן דטרמיניסטי. הבה:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDxDrdLrDajL"
      },
      "source": [
        "SEED = 5785\n",
        "\n",
        "import random\n",
        "from numpy import random as nprnd\n",
        "\n",
        "random.seed(SEED)\n",
        "nprnd.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZSnW0l_n-al"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# מה בדאטא?\n",
        "\n",
        "כמו בניתוח סנטימנט, אנחנו רוצים לדעת עם מה יש לנו עסק. לטעון מתוך UD זה קל עם חבילת datasets, ובשביל לגשת לשדות השונים, ניתן להיעזר ב[דף התיעוד](https://huggingface.co/datasets/universal_dependencies).\n",
        "אותנו מעניין רק הטקסט וחלקי הדיבר UPOS (בשלב הזה) ולכן נסתכל על כמה דוגמאות:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnlL82KYm9G2"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "dataset = load_dataset(\n",
        "   'universal_dependencies', 'te_mtg', trust_remote_code=True)\n",
        "dataset.set_format(type=\"pandas\", columns=[\"text\", \"tokens\", \"upos\"])\n",
        "dataset['validation'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMNqAk-MSUhe"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "המממ. קצת פחות ברור מה שקורה פה מאשר בדוגמת המסמכים השלמים. קודם כל, אנחנו לא דוברים טלוגו. [הנה](https://en.wikipedia.org/wiki/Telugu_language) ערך הויקיפדיה שלה, ו[הנה](https://wals.info/languoid/lect/wals_code_tel) הערך שלה ב-WALS, משאב טיפולוגי שסקרנו בשיעורי המבוא. WALS יספר לנו על תכונות של השפה שאולי יעזרו לנו להבין בהמשך אם יש תופעות שכדאי להתייחס אליהן מפורשות.\n",
        "\n",
        "הדבר השני שאנחנו מתקשים איתו הוא פורמט התגים, שמופיעים כאן אחרי שכבר מופו לאינדקסים ע\"י מי שהזין אותם לשרתי האגינגפייס. למזלנו, דאגו לנו גם לשמירת המיפוי בתוך הדאטאסט, וניתן לגשת אליו מתוך כל אחד מחיתוכי הדאטא (splits).\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsoWmt7NYqP"
      },
      "source": [
        "val_tags = dataset['validation'].features['upos'].feature.names\n",
        "[f'{i:2}: {p}' for (i,p) in enumerate(val_tags)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "סקירת-שפיות קצרה של הדאטא מהתא הקודם תראה לנו שבאמת ברוב המשפטים יש פועל (16), כפי שאנו מצפים מכל שפה, שיש הרבה שמות עצם (0), ושסימני הפיסוק מקבילים לתג המתאים (1).\n",
        "\n",
        "1. רשמו את קוד התכונה (Fid) מערך ה-WALS שבזכותו אנחנו לא מופתעיםות ממיקומי הפעלים שראינו במשפטי הדוגמה.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "jP9YhvY38PoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "---\n",
        "\n",
        "**<תשובה כאן>**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "ZWOAiBisDwPO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8i8-2zeTLk9"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "כיוון שאנחנו חשדניםות מטבענו, ולא נרצה שנאמן את המודל על רשימת תגים מסוימת ואח\"כ נבחן אותו על אינדקסים לא-תואמים (מה שיכול לגרום לכך שכל החיזויים שלנו לשמות עצם יפורשו כחיזויים לפעלים, למשל), נכתוב קוד קצר שמוודא שסדר התגים זהה עבור אימון, ולידציה ומבחן.\n",
        "\n",
        "2. כתבו קוד שמוודא את סדר התגים לשלושת חלקי הדאטאסט. ניתן להשתמש בפונקציית `assert`.\n",
        "**מגישים.ות ביחיד.ה פטוריםות מהסעיף**\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G_d1qP7TnpU"
      },
      "source": [
        "### for exercise 2 ###\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDc3lmI6Y959"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# טוקנייזר\n",
        "\n",
        "בעית הטיקנוז שלנו קלה אפילו יותר מזו שהיתה בניתוח סנטימנט. המסמכים שלנו באים עם חלוקה לטוקנים מראש, ולכן אפשר פשוט להעביר לטוקנייזר שנבנה בתור ברירת מחדל את הפרמטר לפיו המידע שהוא מקבל כבר עבר \"טרום-טוקניזציה\".\n",
        "על-כן:\n",
        "1. נטען את הדאטאסט\n",
        "1. ניצור טוקנייזר פשוט\n",
        "1. נגדיר לו את התמנית הלא ידועה `UNK` ואת תמנית הריפוד `PAD`\n",
        "1. נאמן את הטוקנייזר\n",
        "1. נספר לו איך לרפד.\n",
        "\n",
        "אחר-כך נצטרך לטפל גם בטוקנייזר עבור התגים, בעיקר כדי לשמור על מדיניות ריפוד אחידה (המודולים ב-`torch` יצפו לאורך רצפים אחידים בין הקלט לתגים).\n",
        "בשני המקרים נעשה משהו קצת מלוכלך בשביל ליצור לטוקנייזר מחרוזת כקלט. עבור הטוקנים, נגדיר פונקציה שמכניסה רווחים שאחר-כל האימון של הטוקנייזר יוציא, ועבוד התגים, כיוון שהם נטענו בפורמט `int`, נריץ עליהם פונקציית `str()`.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfVHzTiqWlDA"
      },
      "source": [
        "PAD_ID = 0\n",
        "\n",
        "def map_instance_to_whitespace_tokenizable_text(inst) -> str:\n",
        "    return \" \".join(inst['tokens'])\n",
        "\n",
        "def make_tokenizers():\n",
        "    dataset = load_dataset(\"universal_dependencies\", \"te_mtg\", split=\"train\")\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"<UNK>\"))\n",
        "    tokenizer.pre_tokenizer = WhitespaceSplit()\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"<PAD>\", \"<UNK>\"])\n",
        "    tokenizer.train_from_iterator([map_instance_to_whitespace_tokenizable_text(i) for i in dataset],\n",
        "                                  trainer=trainer,\n",
        "                                  length=len(dataset))\n",
        "    tokenizer.enable_padding(pad_id=PAD_ID, pad_token=\"<PAD>\")\n",
        "\n",
        "    tag_tokenizer = Tokenizer(WordLevel(vocab={str(i): i for i in range(len(val_tags)+1)}))\n",
        "    tag_tokenizer.enable_padding(pad_id=len(val_tags), pad_token=str(len(val_tags)))\n",
        "    return tokenizer, tag_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5X5IGIXUKX"
      },
      "source": [
        "tokenizer, tag_tokenizer = make_tokenizers()\n",
        "\n",
        "tokenizer.save(\"ud-te-tokenizer.json\", pretty=True)\n",
        "tag_tokenizer.save(\"ud-te-tag-tokenizer.json\", pretty=True)\n",
        "\n",
        "print(tokenizer.get_vocab_size())\n",
        "print(tag_tokenizer.get_vocab_size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGKFvg8Gzin"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "שימו לב שקיבלנו אוצר מילים די קטן לטוקנים, כיאה לדאטאסט קטן. הולכים להיות לנו הרבה מאוד `UNK` בולידציה ובטסט.\n",
        "19 תגים זה המספר הרצוי, שכן יש 18 תגים בסכימת UPOS, והוספנו תג ריפוד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1qaENkhcWSs"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# בניית מתייג חלקי דיבר\n",
        "\n",
        "נתחיל בהמרת המעבד שלנו ל-GPU:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SljbOmVeXVyo"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7EvpX4Lc3uf"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## הגדרת המודל\n",
        "\n",
        "המודל הבסיסי שלנו זהה לזה שהשתמשנו בו עבור הרשת לסיווג טקסט שלם, עם הבדל אחד מאוד חשוב: הפלט שלה צריך להיות ברמת הטוקן; לא לוקחים רק את האחרון אלא את כל הסט שיוצא מה-LSTM, ואותו מעבירים לשכבה לינארית.\n",
        "\n",
        "**שימו לב:** בהמשך נראה שפונקציית ההפסד שלנו מקבלת ציונים לא-מנורמלים עבור הקלאסים (חלקי דיבר, במקרה שלנו) ומבצעת את ה-`softmax` כחלק מהחישוב. אל תעבירו את הפלט בפונקציה שמבצעת חישוב דומה.\n",
        "\n",
        "3. ממשו את `__init__()` ואת `forward()`. שימו לב לפרמטרים שהשתנו ביחס להדרכת תיוג המסמכים.\n",
        "\n",
        "![](https://discuss.pytorch.org/uploads/default/original/2X/e/e7496a33d835f085d800ee17c0ade05895a89551.png)<br>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4z8A8RdXiQl"
      },
      "source": [
        "class PosTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_dim: int,\n",
        "                 hidden_size: int,\n",
        "                 num_tags: int,\n",
        "                 num_layers: int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        ### for exercise 3.1 ###\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "\n",
        "        ### for exercise 3.2 ###\n",
        "\n",
        "        raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3BB1099OyZK"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## אימון ו-ולידציה\n",
        "\n",
        "ההבדל העיקרי בפרקטיקת האימון אל מול סיווג מסמכים היא שיש גרדיאנט שמחושב עבור כל אחד מהטוקנים בנפרד: לכל אצווה (batch) יהיו לנו מספר תחזיות לא כגודלה אלא כסכום אורכי המשפטים שבה.\n",
        "עיינו בקפידה ב[תיעוד](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) מודול ההפסד שנשתמש בו וחישבו היטב מה הקלט שלו צריך להיות.\n",
        "\n",
        "4.1 ממשו את חישוב ההפסד ופעפועו. שימו לב לגדלי הטנסורים המשתתפים. שני רמזים בהקשר זה:\n",
        "* אין לדאוג עדיין לטוקני הריפוד. אנחנו לא נרצה להשתמש בתחזיות שלהם כמובן, אבל הטיפול בהם קורה בשלב אתחול ההפסד.\n",
        "* גשו לתיעוד של `torch.tensor` ועמדו על ההבדל בין הפעולות `view()` ו-`permute()`.\n",
        "* **מגישים ביחיד.ה פטוריםות מהסעיף - פנו אליי עד ליום 10/12 בשעה 13:59 לקבלת שורות הקוד (מילואימניקים עד 14/12 ב-23:59).**\n",
        "\n",
        "4.2. ממשו את חישוב המטריקה. אנו נמדוד דיוק פשוט (accuracy), ולצורך כך אותחלו עבורכם משתני-עזר לפני הלולאה. כאן אנחנו כן דואגים לטוקני הריפוד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX7neNCaX07e"
      },
      "source": [
        "def train(model: PosTagger,\n",
        "          optimizer: optim.Optimizer,\n",
        "          loss_fn: nn.CrossEntropyLoss,\n",
        "          dataloader: DataLoader) -> dict:\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        sentences = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        probs = model(sentences)\n",
        "\n",
        "        ### for exercise 4.1 ###\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        ###\n",
        "\n",
        "        preds = probs.argmax(dim=2)\n",
        "\n",
        "        ### for exercise 4.2 ###\n",
        "\n",
        "        pass\n",
        "\n",
        "        ###\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def evaluate(model: PosTagger,\n",
        "             dataloader: torch.utils.data.DataLoader) -> dict:\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # operations done in this block will not contribute to gradients\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            sentences = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            probs = model(sentences)\n",
        "            preds = probs.argmax(dim=2)\n",
        "\n",
        "            ### for exercise 4.2 ###\n",
        "\n",
        "            ### (the same code from train() should work)\n",
        "\n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkwR_UESPvjV"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# רגע האמת\n",
        "\n",
        "נחבר הכל ביחד. נגדיר את הקבועים שלנו, שבהמשך יהיו היפר-פרמטרים.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmL1nlMV_aA"
      },
      "source": [
        "BATCH_SIZE = 24\n",
        "EMB_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwzQHeJiWQKm"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "נגדיר פונקציית-עזר לחילוץ מחרוזות האינדקסים מתוך מיפויי התגים, ונטען בעזרתה את הדאטאסט.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlGbCxPVVJVy"
      },
      "source": [
        "def deep_stringify(x):\n",
        "    if type(x) == int:\n",
        "        return str(x)\n",
        "    return [deep_stringify(a) for a in x]\n",
        "\n",
        "dataset = load_dataset(\"universal_dependencies\", \"te_mtg\")\n",
        "dataset = dataset.map(lambda ins: {\n",
        "    \"input_ids\": [e.ids for e in tokenizer.encode_batch(ins['tokens'],\n",
        "                                                        is_pretokenized=True)],\n",
        "    \"labels\": [e.ids for e in tag_tokenizer.encode_batch(deep_stringify(ins['upos']),\n",
        "                                                        is_pretokenized=True)],\n",
        "}, batched=True, batch_size=BATCH_SIZE)\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"])\n",
        "\n",
        "train_dataloader = DataLoader(dataset[\"train\"], batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(dataset[\"validation\"], batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(dataset[\"test\"], batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGUSebxWgbC"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "נאתחל מודל, מאפטם ופונקציית הפסד.\n",
        "\n",
        "5. אתחלו את פונקציית ההפסד.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkqjbfQDYAh5"
      },
      "source": [
        "model = PosTagger(embedding_dim=EMB_DIM,\n",
        "                  hidden_size=HIDDEN_DIM,\n",
        "                  num_layers=NUM_LAYERS,\n",
        "                  num_tags=len(val_tags)).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "### for exercise 5\n",
        "\n",
        "loss_fn = None\n",
        "\n",
        "###\n",
        "\n",
        "train_accuracies = []\n",
        "validation_accuracies = []\n",
        "for epoch in range(EPOCHS):\n",
        "    train_acc = train(model, optimizer, loss_fn,\n",
        "                          train_dataloader)\n",
        "    val_acc = evaluate(model, val_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}:\")\n",
        "    print(f\"Training Accuracy: {100 * train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy: {100 * val_acc:.2f}%\")\n",
        "    train_accuracies.append(train_acc)\n",
        "    validation_accuracies.append(val_acc)\n",
        "\n",
        "plt.title(\"Accuracy by Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(train_accuracies, label=\"Training\")\n",
        "plt.plot(validation_accuracies, label=\"Validation\")\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmOGxQclpgeM"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# ניתוח\n",
        "\n",
        "6. בתיבת הטקסט להלן, תארו את הגרף שיצא לכםן לעיל. הציעו לפחות שני שינויים בהיפר-פרמטרים שלדעתכןם עשויים לשפר את התוצאה **וממשו אותם**. לכל ניסוי שכפלו את תיבת הקוד לעיל, שנו את מה שצריך, והריצו מחדש. **השתמשו בשמות משתנים חדשים עבור המודלים והתוצאות**. ניתן לוותר על הדפסות המספרים באפוקי הביניים ולהסתפק בתוצאות הסוף ובגרף.\n",
        "\n",
        "7. שנו מאפיין של הניסוי ש**אינו** אחד מההיפר-פרמטרים המוגדרים. למשל, השתמשו בקלאס אחר מ-pytorch עבור הרשת הנשנית, המאפטם, או משהו אחר לבחירתכןם. או הוסיפו שכבה לינארית למודל.\n",
        "**מגישים ביחיד.ה פטוריםות מסעיף 7**\n",
        "\n",
        "האם השינויים אכן הועילו?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKmLgXFAYsdU"
      },
      "source": [
        "## <דווחו כאן>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHDyp3C3YBAv"
      },
      "source": [
        "### for exercise 6-7 ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiHHRen_YDe-"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "## טסט\n",
        "\n",
        "8. מצאו את המודל הטוב ביותר מאלה שניסיתם עד כה והריצו (פעם אחת בלבד) על הטסט. הקבוצה עם התוצאה הטובה ביותר תקבל בונוס נקודה לציון הסופי בקורס.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBuAY515Y4Oy"
      },
      "source": [
        "### for exercise 8 ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7vROGFtTefk"
      },
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "# העשרה - שיכונים מן המוכן\n",
        "\n",
        "למי שמעונייןת, ניתן להוריד שיכונים (embeddings) של טלוגו ממאגר שנקרא fastText. הקוד להורדת המודל, טעינתו והתאמתו למימד הבעייה שלנו נתון. שינוי הטוקנייזר והמודל לצורך שימוש במתייג שלנו - עליכןם. **ללא ציון**.\n",
        "\n",
        "שימו לב שהורדת השיכונים לוקחת זמן רב (מדובר בכ-4GB). היאזרו בסבלנות או בפרק מנטפליקס.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1e3VbpXZLCa"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrDARO-sTS7T"
      },
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('te', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.te.300.bin')\n",
        "fasttext.util.reduce_model(ft, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DA6S6ytDd2b"
      },
      "source": [
        "!rm cc.te.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BHyJs8jHIGz"
      },
      "source": [
        "len(ft.get_words())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBYb1xzHQw4"
      },
      "source": [
        "ft.get_words()[5000:5005]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}